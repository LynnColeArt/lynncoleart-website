---
layout: post.njk
title: Current thinking on Image Generators and Training Ethics
date: '2025-04-02T09:19:00.000Z'
tags:
  - ai
  - ai art
  - stable diffusion
  - data governance
  - training
  - ethics
excerpt: A discussion on training ethics and the Commons
draft: false
---
My current thoughts on Ai Art and Ai in general.

1. Training does not equal replication - usually.

There are exceptions to this. And there are valid reasons an artist would want to replicate something. But I don't see a distinction that makes it less artful.

Prompting is an artform. And despite the best efforts of ai labs and developers to make it easier to do, it still requires artistic practice to get something that qualifies as personal expression out of it.

So it counts as art, regardless.

Your personal appreciation of this artform may vary.

But you don't have to like something for it to be considered valid art.

You don't even need to understand it.

2. If big companies are going to harvest the commons to train models, without making them open source and thereby contributing their contributions BACK to the commons... I think they should pay for the right to do it.

I think people who don't understand AI like to make arguments about corporate AI. And I don't think those arguments against corporate AI are bad, or poorly reasoned.

There are a thousand reasons to be frustrated with corporate AI. From the environmental footprint, to security, to data privacy, to training, and the list goes on.

But... the place I think the line makes sense there is in this question: What are you contributing to the greater good?

There's this thing that's going on in AI that I don't like. Commercial developers coming in, stealing open source code and workflows, and putting out their "products" which are essentially wrappers or motes around open source products.

This is going to happen.

Question is... who's worse?

A company like meta that uses billions of lines of open source code to produce models that they release under open licenses, that can be worked with and worked on freely?

Or the interest that takes a couple of diffusion models, makes some useful tweaks, contributes nothing back, and calls it a "service" so they can sell it back to you?

I would argue the latter is worse, because the second scenario does nothing to further the science, detracts from the work and acknowledgement of the actual contributors (most of whom aren't being paid), and contributes nothing to the community, to sell a product that it does not own.

These guys put no money and little time into developing, all the while rebranding it -- lying, about what they're selling and where the "product" came from.

All the while exploiting  a community that is easily impressed by sparkly things.

This is frequently done in violation of open source licenses.

So why no accountability for these guys?

We all know who's doing it.

I think we should be thinking about the openness of things. I think we should care about where all this is going. I think we should care about fairness, to artists and developers.

The corporations need open source code more than developers need corporate models and ui tooling.

These things are not equal.

The abuse needs to stop.

If the (sometimes ironically named) corporates are going to keep moating people's work away, while contributing nothing to the larger conversation... they need to start paying for the privilege.
